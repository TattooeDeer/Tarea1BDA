---
title: "Críticas de Apps en Google Play Store"
author:
- Ignacio Loayza.
- Miguel Huichaman.
- Jorge Caullán.
date: "15/04/2019"
output:
  html_document:
    df_print: paged
---

En esta ocasión se estudiaran las críticas a varias aplicaciones de la Google Play Store.
El código para importar los datos a la base de datos, asi como también el esquema de jerarquía con el que se modelaron los datos puede ser encontrado en el repositorio del proyecto.

```{r}
# Paquetes requeridos
list.of.packages <- c("SnowballC", "tm", "mongolite", "wordcloud", "RColorBrewer", "fpc", "cluster")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)

library("SnowballC")
library("NLP")
library("tm")
library("mongolite")
library("wordcloud")
library("RColorBrewer")
library("fpc")
library("cluster")


if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
BiocManager::install()
BiocManager::install("graph", version = "3.8")
BiocManager::install("Rgraphviz", version = "3.8")
library("Rgraphviz")

categories_mongo <- mongo(collection = "categories", db = "tarea1BDA", url = 'mongodb://127.0.0.1:27017')
categories <- categories_mongo$find('{}','{"category":1, "_id":0}') # Con esto tendremos una lista con todas las categorias que hay
```

## 1.- ¿Qué categorias tienen mayor ranking promedio?
Nos interesa conocer el puntaje promedio de cada categoría y ordernarlas para encontrars aquellas que poseen mayor puntaje promedio.


```{r}
df_ratings <- data.frame(categ = as.character(character()), mean_rating = as.character(character()), stringsAsFactors = FALSE)

for (cat in categories$category){
  category_name <- cat
  query_cat <- sprintf('{"category":"%s"}',category_name)
  cat_ratings <- categories_mongo$find(query_cat,'{"apps.Rating":1, "_id":0}')
  category_mean_rating <- mean(as.numeric(as.character(unlist(cat_ratings[[1]]))))
  #temp_list <- list(categ=as.character(category_name), mean_rating=category_mean_rating)
  temp_df <- data.frame(categ = as.character(category_name), mean_rating=category_mean_rating, stringsAsFactors = FALSE)
  df_ratings <- rbind(df_ratings,temp_df)
}

newdata <- df_ratings[order(df_ratings$mean_rating, decreasing = TRUE),]
barplot(newdata[,2], names.arg = newdata[,1])  # Barplot horrible
print(newdata[0:3,])
```

Las categorías de apps con mayor puntaje promedio son _"Eventos"_, _"Educación"_ y _"Arte y diseño"_, hay que notar, sin embargo, que la media del puntaje de las categorias es $4.202$ y con una desviación estándar de $0.106$ y una media mínima de $3.971$, lo que hace poco distinguibles las categorías en cuanto a puntaje, además de que en general todas las categorías tienen un puntaje medio cercano al máximo.
```{r}
summary(newdata$mean_rating)
sd(newdata$mean_rating)
```


## 2.- Términos descriptivos a los que más se hace alusión
Ahora, se estudiará la repetición de términos considerando todas las reviews disponibles.

Primero almacenaremos los textos de todas las reviews en formato .txt, separadas inmediatamente por sentimiento, para poder conformar de manera formal el corpus:
```{r}

positive <- categories_mongo$find('{}','{"cumulated_reviews.positives":1, "_id":0}')
negative <- categories_mongo$find('{}','{"cumulated_reviews.negatives":1, "_id":0}')
neutral <- categories_mongo$find('{}','{"cumulated_reviews.neutrals":1, "_id":0}')

#all reviews
rev_all <- c(positive[,1],negative[,1],neutral[,1])
vector_reviews <- VectorSource(rev_all)

```
Cargamos el corpus leyendo los textos de todas las reviews.

```{r}
docs <- VCorpus(vector_reviews)

# Transformador de espacios
toSpace <- content_transformer(function(x, pattern) {return (gsub(pattern, " ", x))})

# Limpieza de puntuacion
# Usar el transformador anterior para eliminar comas, dos puntos y otros...
docs <- tm_map(docs, toSpace, "-")
docs <- tm_map(docs, toSpace, ":")
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, toSpace, "’")
docs <- tm_map(docs, toSpace, "‘")
docs <- tm_map(docs, toSpace, " -")

# There are some parasite words that need cleaning
docs <- tm_map(docs, toSpace, "data frame")
docs <- tm_map(docs, toSpace, "Translated_Review")
docs <- tm_map(docs, toSpace, "datafram")

# Transformar todo a minusculas
docs <- tm_map(docs,content_transformer(tolower))

# Eliminar digitos
docs <- tm_map(docs, removeNumbers)

# Remover stopwords usando la lista estándar de tm
docs <- tm_map(docs, removeWords, stopwords("english"))

# Borrar todos los espacios en blanco extraños
docs <- tm_map(docs, stripWhitespace)

# Stemming
docs <- tm_map(docs,stemDocument)
#writeLines(as.character(docs[[1]]))

# Lemmatization (toma en cuenta el contexto) ... podrían hacerse varias más
docs <- tm_map(docs, content_transformer(gsub), pattern = "organiz", replacement = "organ")
docs <- tm_map(docs, content_transformer(gsub), pattern = "organis", replacement = "organ")
docs <- tm_map(docs, content_transformer(gsub), pattern = "andgovern", replacement = "govern")
docs <- tm_map(docs, content_transformer(gsub), pattern = "inenterpris", replacement = "enterpris")
docs <- tm_map(docs, content_transformer(gsub), pattern = "team-", replacement = "team")

#writeLines(as.character(docs[[1]]))

# Matriz de documentos - términos (MDT)
dtm <- DocumentTermMatrix(docs, control=list(wordLengths=c(4, 20)))
# Matriz de 30 x 4200, en la cual un 89% de filas son cero
dtm
```
```{r}
freq <- colSums(as.matrix(dtm))
ord <- order(freq,decreasing=TRUE)
print("Términos más frecuentes: ")
print(freq[head(ord)])
```
Se puede observar que los términos más frecuentes en todas las reviews suelen ser positivos, esto puede explicar los altos puntajes que tienen las medias de los puntajes de todas las categorías.

También se puede notar que de los seis términos mostrados, los cuatro que se relacionan con un sentiemiento positivo son palabras que expresan este sentiemiento de forma marcada, siendo de hecho _"love"_ y _"great"_ los segundo y terceros términos que más se repiten.

El hecho de que la palabra _"game"_ sea la que más se repite no aporta mayor información pues el contexto esta implícito.

```{r}
plot(freq[ord], main = "Frecuencia de términos en los documentos", ylab="Frecuencia de aparición")
```

Se puede observar la frecuencia de términos en el documento, la cual como es de esperarse, se manifiesta de acuerdo a la Ley de Zipf: Algunos pocos términos son exponencialmente más frecuentes que los demás del documento.


## 3) Relaciones entre términos descriptivos

A continuación se presenta el gráfico de relación entre términos presentes en los documentos.
```{r}
freq.terms <- findFreqTerms(dtm,lowfreq=4700)
plot(dtm, term = freq.terms, corThreshold = 0.90, weighting = T)
```
Se puede observar que los términos comunes estan fuertemente relacionados (correlation threshold = $0.90$) en cuanto a ocurrencia conjunta en los reviews pues todas las aristas se muestran en negrita. Se puede ver que la palabra `game` solo esta fuertemente relacionada con `time`, probablemente debido a los reviews que comentan sobre el tiempo de juego. También se puede notar que existe una clique entre todos los términos, exceptuado `game`, y dichos términos son casi en su totalidad asociados a sentimientos positivos, luego, el conjunto de términos con mayor repetición en los reviews estan casi todos asociados a sentimientos positivos y tienen una ocurrencia altamente correlacionada.


## 4) Términos más repetitivos 3 categorías diferentes

Cargamos el corpus leyendo los textos de todas las reviews de las categorías ART_AND_DESIGN, EDUCATION, FINANCE.

### 4.1) Categoria _Art and Design_

```{r}
positives_art <- categories_mongo$find('{"category": "ART_AND_DESIGN"}','{"cumulated_reviews.positives":1, "_id":0}')
negatives_art <- categories_mongo$find('{"category": "ART_AND_DESIGN"}','{"cumulated_reviews.negatives":1, "_id":0}')
neutrals_art <- categories_mongo$find('{"category": "ART_AND_DESIGN"}','{"cumulated_reviews.neutrals":1, "_id":0}')

rev_3_art <- c(positives_art[,1],negatives_art[,1],neutrals_art[,1])
vector_3_art_reviews <- VectorSource(rev_3_art)
```
Cargamos el corpus leyendo los textos de todas las reviews de estas categorías.
```{r}

docs3 <- VCorpus(vector_3_art_reviews)

# Transformador de espacios
toSpace <- content_transformer(function(x, pattern) {return (gsub(pattern, " ", x))})

# Limpieza de puntuacion
# Usar el transformador anterior para eliminar comas, dos puntos y otros...
docs3 <- tm_map(docs3, toSpace, "-")
docs3 <- tm_map(docs3, toSpace, ":")
docs3 <- tm_map(docs3, removePunctuation)
docs3 <- tm_map(docs3, toSpace, "’")
docs3 <- tm_map(docs3, toSpace, "‘")
docs3 <- tm_map(docs3, toSpace, " -")

# There are some parasite words that need cleaning
docs3 <- tm_map(docs3, toSpace, "data frame")
docs3 <- tm_map(docs3, toSpace, "Translated_Review")
docs3 <- tm_map(docs3, toSpace, "datafram")

# Transformar todo a minusculas
docs3 <- tm_map(docs3,content_transformer(tolower))

# Eliminar digitos
docs3 <- tm_map(docs3, removeNumbers)

# Remover stopwords usando la lista estándar de tm
docs3 <- tm_map(docs3, removeWords, stopwords("english"))

# Borrar todos los espacios en blanco extraños
docs3 <- tm_map(docs3, stripWhitespace)

# Stemming
docs3 <- tm_map(docs3,stemDocument)
#writeLines(as.character(docs[[1]]))

# Lemmatization (toma en cuenta el contexto) ... podrían hacerse varias más
docs3 <- tm_map(docs3, content_transformer(gsub), pattern = "organiz", replacement = "organ")
docs3 <- tm_map(docs3, content_transformer(gsub), pattern = "organis", replacement = "organ")
docs3 <- tm_map(docs3, content_transformer(gsub), pattern = "andgovern", replacement = "govern")
docs3 <- tm_map(docs3, content_transformer(gsub), pattern = "inenterpris", replacement = "enterpris")
docs3 <- tm_map(docs3, content_transformer(gsub), pattern = "team-", replacement = "team")

#writeLines(as.character(docs[[1]]))

# Matriz de documentos - términos (MDT)
dtm3 <- DocumentTermMatrix(docs3, control=list(wordLengths=c(4, 20)))
# Matriz de 30 x 4200, en la cual un 89% de filas son cero
dtm3
```
```{r}
freq3 <- colSums(as.matrix(dtm3))
ord3 <- order(freq3,decreasing=TRUE)
print("Términos más frecuentes para la categoría `Art and Design`: ")
print(freq3[head(ord3)])
```
Se puede ver que los términos más comunes para la cetagoría de arte y diseño son principalemente términos asociados a sentimientos positivos, con la excepción de los términos `make`, `color` y `picture`, además, el término más repetido es `color`, el cual tiene bastante relación con la categoría en sí por lo que es esperable.

### 4.2) Categoría _Education_:
```{r}
positives_edu <- categories_mongo$find('{"category": "EDUCATION"}','{"cumulated_reviews.positives":1, "_id":0}')
negatives_edu <- categories_mongo$find('{"category": "EDUCATION"}','{"cumulated_reviews.negatives":1, "_id":0}')
neutrals_edu <- categories_mongo$find('{"category": "EDUCATION"}','{"cumulated_reviews.neutrals":1, "_id":0}')

rev_3_edu <- c(positives_edu[,1],negatives_edu[,1],neutrals_edu[,1])
vector_3_edu_reviews <- VectorSource(rev_3_edu)


docs3 <- VCorpus(vector_3_edu_reviews)

# Transformador de espacios
toSpace <- content_transformer(function(x, pattern) {return (gsub(pattern, " ", x))})

# Limpieza de puntuacion
# Usar el transformador anterior para eliminar comas, dos puntos y otros...
docs3 <- tm_map(docs3, toSpace, "-")
docs3 <- tm_map(docs3, toSpace, ":")
docs3 <- tm_map(docs3, removePunctuation)
docs3 <- tm_map(docs3, toSpace, "’")
docs3 <- tm_map(docs3, toSpace, "‘")
docs3 <- tm_map(docs3, toSpace, " -")

# There are some parasite words that need cleaning
docs3 <- tm_map(docs3, toSpace, "data frame")
docs3 <- tm_map(docs3, toSpace, "Translated_Review")
docs3 <- tm_map(docs3, toSpace, "datafram")

# Transformar todo a minusculas
docs3 <- tm_map(docs3,content_transformer(tolower))

# Eliminar digitos
docs3 <- tm_map(docs3, removeNumbers)

# Remover stopwords usando la lista estándar de tm
docs3 <- tm_map(docs3, removeWords, stopwords("english"))

# Borrar todos los espacios en blanco extraños
docs3 <- tm_map(docs3, stripWhitespace)

# Stemming
docs3 <- tm_map(docs3,stemDocument)
#writeLines(as.character(docs[[1]]))

# Lemmatization (toma en cuenta el contexto) ... podrían hacerse varias más
docs3 <- tm_map(docs3, content_transformer(gsub), pattern = "organiz", replacement = "organ")
docs3 <- tm_map(docs3, content_transformer(gsub), pattern = "organis", replacement = "organ")
docs3 <- tm_map(docs3, content_transformer(gsub), pattern = "andgovern", replacement = "govern")
docs3 <- tm_map(docs3, content_transformer(gsub), pattern = "inenterpris", replacement = "enterpris")
docs3 <- tm_map(docs3, content_transformer(gsub), pattern = "team-", replacement = "team")

#writeLines(as.character(docs[[1]]))

# Matriz de documentos - términos (MDT)
dtm3 <- DocumentTermMatrix(docs3, control=list(wordLengths=c(4, 20)))
# Matriz de 30 x 4200, en la cual un 89% de filas son cero
dtm3
```
```{r}
freq3 <- colSums(as.matrix(dtm3))
ord3 <- order(freq3,decreasing=TRUE)
print("Términos más frecuentes para la categoría `Education`: ")
print(freq3[head(ord3)])
```

Se puede observar que el término más común es `learn` el cual tiene directa relación con la categoría, además, se puede ver nuevamente que hay términos asociados con sentimientos positivos como `great` y `good`, si embargo, en menor cantidad que para la categoría anterior. El término `help` es interesante pues puede tener relación con algún aspecto positivo que se esté tratando de explicar en una review, por ejemplo, "This app helped me to ...".

### 4.3) Categoría _Finance_:

```{r}
positives_fin <- categories_mongo$find('{"category": "FINANCE"}','{"cumulated_reviews.positives":1, "_id":0}')
negatives_fin <- categories_mongo$find('{"category": "FINANCE"}','{"cumulated_reviews.negatives":1, "_id":0}')
neutrals_fin <- categories_mongo$find('{"category": "FINANCE"}','{"cumulated_reviews.neutrals":1, "_id":0}')

rev_3_fin <- c(positives_fin[,1],negatives_fin[,1],neutrals_fin[,1])
vector_3_fin_reviews <- VectorSource(rev_3_fin)


docs3 <- VCorpus(vector_3_fin_reviews)

# Transformador de espacios
toSpace <- content_transformer(function(x, pattern) {return (gsub(pattern, " ", x))})

# Limpieza de puntuacion
# Usar el transformador anterior para eliminar comas, dos puntos y otros...
docs3 <- tm_map(docs3, toSpace, "-")
docs3 <- tm_map(docs3, toSpace, ":")
docs3 <- tm_map(docs3, removePunctuation)
docs3 <- tm_map(docs3, toSpace, "’")
docs3 <- tm_map(docs3, toSpace, "‘")
docs3 <- tm_map(docs3, toSpace, " -")

# There are some parasite words that need cleaning
docs3 <- tm_map(docs3, toSpace, "data frame")
docs3 <- tm_map(docs3, toSpace, "Translated_Review")
docs3 <- tm_map(docs3, toSpace, "datafram")

# Transformar todo a minusculas
docs3 <- tm_map(docs3,content_transformer(tolower))

# Eliminar digitos
docs3 <- tm_map(docs3, removeNumbers)

# Remover stopwords usando la lista estándar de tm
docs3 <- tm_map(docs3, removeWords, stopwords("english"))

# Borrar todos los espacios en blanco extraños
docs3 <- tm_map(docs3, stripWhitespace)

# Stemming
docs3 <- tm_map(docs3,stemDocument)
#writeLines(as.character(docs[[1]]))

# Lemmatization (toma en cuenta el contexto) ... podrían hacerse varias más
docs3 <- tm_map(docs3, content_transformer(gsub), pattern = "organiz", replacement = "organ")
docs3 <- tm_map(docs3, content_transformer(gsub), pattern = "organis", replacement = "organ")
docs3 <- tm_map(docs3, content_transformer(gsub), pattern = "andgovern", replacement = "govern")
docs3 <- tm_map(docs3, content_transformer(gsub), pattern = "inenterpris", replacement = "enterpris")
docs3 <- tm_map(docs3, content_transformer(gsub), pattern = "team-", replacement = "team")

#writeLines(as.character(docs[[1]]))

# Matriz de documentos - términos (MDT)
dtm3 <- DocumentTermMatrix(docs3, control=list(wordLengths=c(4, 20)))
# Matriz de 30 x 4200, en la cual un 89% de filas son cero
dtm3
```

```{r}
freq3 <- colSums(as.matrix(dtm3))
ord3 <- order(freq3,decreasing=TRUE)
print("Términos más frecuentes para la categoría `Finance`: ")
print(freq3[head(ord3)])
```


En el caso de la categoría _`Finanzas`_ no hay términos asociados a ningún sentimiento en particular, en lugar de eso, parece ser que los términos más populares son utilizaos en descripciónes utilitarias de las apps y características de las mismas. El término más común es `work` y tiene bastante sentido considerando que probablemente la mayoría de estas aplicaciones estan pensadas para asistir a las personas en el trabajo.


## 5) Terminos mas comunes en comentarios negativos y positivos
De una manera analoga a la anterior, se cargan los comentarios positivos y negativos de todas las categorias
```{r}
positives <- categories_mongo$find('{}','{"cumulated_reviews.positives":1, "_id":0}')
negatives <- categories_mongo$find('{}','{"cumulated_reviews.negatives":1, "_id":0}')

vector_positive_reviews <- VectorSource(c(positives[,1]))
vector_negative_reviews <- VectorSource(c(negatives[,1]))

Pdocs <- VCorpus(vector_positive_reviews)
Ndocs <- VCorpus(vector_negative_reviews)

# Limpieza de puntuacion
# Usar el transformador anterior para eliminar comas, dos puntos y otros...
Pdocs <- tm_map(Pdocs, toSpace, "-")
Pdocs <- tm_map(Pdocs, toSpace, ":")
Pdocs <- tm_map(Pdocs, removePunctuation)
Pdocs <- tm_map(Pdocs, toSpace, "’")
Pdocs <- tm_map(Pdocs, toSpace, "‘")
Pdocs <- tm_map(Pdocs, toSpace, " -")

Ndocs <- tm_map(Ndocs, toSpace, "-")
Ndocs <- tm_map(Ndocs, toSpace, ":")
Ndocs <- tm_map(Ndocs, removePunctuation)
Ndocs <- tm_map(Ndocs, toSpace, "’")
Ndocs <- tm_map(Ndocs, toSpace, "‘")
Ndocs <- tm_map(Ndocs, toSpace, " -")

# There are some parasite words that need cleaning
Pdocs <- tm_map(Pdocs, toSpace, "data frame")
Pdocs <- tm_map(Pdocs, toSpace, "Translated_Review")
Pdocs <- tm_map(Pdocs, toSpace, "datafram")

Ndocs <- tm_map(Ndocs, toSpace, "data frame")
Ndocs <- tm_map(Ndocs, toSpace, "Translated_Review")
Ndocs <- tm_map(Ndocs, toSpace, "datafram")

# Transformar todo a minusculas
Pdocs <- tm_map(Pdocs,content_transformer(tolower))
Ndocs <- tm_map(Ndocs,content_transformer(tolower))

# Eliminar digitos
Pdocs <- tm_map(Pdocs, removeNumbers)
Ndocs <- tm_map(Ndocs, removeNumbers)

# Remover stopwords usando la lista est?ndar de tm
Pdocs <- tm_map(Pdocs, removeWords, stopwords("english"))
Ndocs <- tm_map(Ndocs, removeWords, stopwords("english"))

# Borrar todos los espacios en blanco extraños
Pdocs <- tm_map(Pdocs, stripWhitespace)
Ndocs <- tm_map(Ndocs, stripWhitespace)

# Stemming
Pdocs <- tm_map(Pdocs,stemDocument)
Ndocs <- tm_map(Ndocs,stemDocument)

# Lemmatization (toma en cuenta el contexto) ... podr?an hacerse varias m?s
Pdocs <- tm_map(Pdocs, content_transformer(gsub), pattern = "organiz", replacement = "organ")
Pdocs <- tm_map(Pdocs, content_transformer(gsub), pattern = "organis", replacement = "organ")
Pdocs <- tm_map(Pdocs, content_transformer(gsub), pattern = "andgovern", replacement = "govern")
Pdocs <- tm_map(Pdocs, content_transformer(gsub), pattern = "inenterpris", replacement = "enterpris")
Pdocs <- tm_map(Pdocs, content_transformer(gsub), pattern = "team-", replacement = "team")

Ndocs <- tm_map(Ndocs, content_transformer(gsub), pattern = "organiz", replacement = "organ")
Ndocs <- tm_map(Ndocs, content_transformer(gsub), pattern = "organis", replacement = "organ")
Ndocs <- tm_map(Ndocs, content_transformer(gsub), pattern = "andgovern", replacement = "govern")
Ndocs <- tm_map(Ndocs, content_transformer(gsub), pattern = "inenterpris", replacement = "enterpris")
Ndocs <- tm_map(Ndocs, content_transformer(gsub), pattern = "team-", replacement = "team")

# Matriz de documentos - t?rminos (MDT)
Pdtm <- DocumentTermMatrix(Pdocs, control=list(wordLengths=c(4, 20)))
Ndtm <- DocumentTermMatrix(Ndocs, control=list(wordLengths=c(4, 20)))
# Matriz de 30 x 4200, en la cual un 89% de filas son cero
Pdtm
Ndtm
```

Los terminos de mayor Frecuencia de los terminos positivos estan dados por:
```{r}
freqp <- colSums(as.matrix(Pdtm))
ordn <- order(freqp,decreasing=TRUE)
print(freqp[head(ordn)])
```
El término más común en el caso de los comentarios positivos es `game`, lo que nos indica que al parecer la mayoría de las reviews positivas se pueden encontrar en aplicaciones de juegos. Por otro lado, están varios términos ya vistos que hacen relación con la emocionalidad positiva del review. Finalmente, se puede ver que `time` esta asociado con reviews de sentimiento positivo.


Y los terminos de mayor Frecuencia de los terminos negativos estan dados por:
```{r}
freqn <- colSums(as.matrix(Ndtm))
ordn <- order(freqn,decreasing=TRUE)
print(freqn[head(ordn)])
```
En el caso de los reviews de sentimiento negativo se puede observar que curiosamente, al igual que en aquellos de sentimiento positivo, el término más común es `game`, esto nos hace contraste con la conclusión anterior puesto que gran parte de los reviews negativos hacen alusión a juegos también, concluimos entonces que los juegos son un tipo de aplicación con reviews bastante dispersos y extremos. Otro términos encontrado: `play`, también hacen alusión a juegos.

El resto de los términos curiosamente no expresan sentimientos negativos, probablemente tengan una connotación negativa en conjunto con otros términos de la misma oración.

## 6) Nube de palabras con N términos más comunes

Se decidió usar un N = 50 para los términos más comunes, los que serán obtenidos del primer análisis de frecuencias.

```{r}
# Setear un valor semilla
set.seed(42)
# Nube de palabras en blanco y negro; palabras con frecuencia mínima de 1000
wordcloud(names(freq), freq, min.freq=1000, max.words= 60, colors=brewer.pal(6,"Dark2"))
```
Podemos ver claramente que los términos representativos que hemos encontrado en el análisis de sentimientos están presentes con mayor tamaño en la nube de palabras, los tèrminos con menor tamaño ortorgan poca información por si solos por lo que quizás son relevantes en un determinado contexto.

```{r}
dtmr2 <- removeSparseTerms(dtm, sparse = 0.05)
inspect(dtmr2)

distMatrix <- dist(t(dtmr2), method= "manhattan")# probar con otros métodos

nroClusters <- 5 # as many as categories

kmeans_fit <- kmeans(distMatrix, nroClusters)
hclust_fit <- hclust(distMatrix, method = "ward")

clusplot(as.matrix(distMatrix), kmeans_fit$cluster, color=T, shade=T, labels=1, lines=0, main = "5-Means Clustering")
clusplot(as.matrix(distMatrix), kmeans_fit$cluster, color=T, shade=T, labels=2, lines=0, main = "5-Means Clustering")
# Dendrograma
plot(hclust_fit, cex=0.2, hang=-1, main = "Dendrograma de Clusters de Palabras")
#clusplot(as.matrix(distMatrix), k_fitfit$cluster, color=T, shade=T, labels=3, lines=0, main = "Cluster jerárquico")
# Para chequear palabras representativas dentro de cada cluster 
for (i in 1: nroClusters)
{
  cat(paste("cluster ", i, ": ", sep = ""))
  s <- sort(kfit$centers[i,], decreasing = T)
  cat(names(s)[1:5], "\n")
}
```
Se puede ver que en el caso de clustering particional (KMeans) la mayoría de los clusters se concentran en la zona de alta densidad de la esquina inferior, mientras que un cluster centrado en un único término `game` nos muestra claramente que este término tiene características distintas a los demás, como se vio en el análisis de repetición de términos, `game` es un ´termino que se repite mucho tanto en sentimientos positivos como negativos.

Con respecto a clustering jerárquico, cortando al segundo nivel se puede extraer tres clusters.
